# Wholeâ€‘Slide Imaging System (WSI) â€” Deepâ€‘Learning Autofocus & Pyramidal OMEâ€‘TIFF

> Python Â· TensorFlow/PyTorch Â· OpenCV Â· NVIDIA Jetson Â· Dask/Zarr Â· OMEâ€‘TIFF

This repository contains core components of a Wholeâ€‘Slide Imaging pipeline built for highâ€‘throughput digital pathology. It includes a deepâ€‘learning autofocus regressor for inline focus estimation, a stitched wholeâ€‘slide image (WSI) assembly flow, and a memory/I/Oâ€‘optimized exporter that produces pyramidal OMEâ€‘TIFF suitable for viewers and downstream analysis.

---

## ğŸš€ Highlights

- **Deepâ€‘Learning Autofocus (Regressor):** Learns continuous focus distance directly from patches, enabling **Â±0.002â€¯mm** focus accuracy across multiâ€‘resolution slides.
- **Seamless WSI Capture & Stitching:** Implements an **optimal capture strategy (patented)** to minimize seams and parallax while maximizing inâ€‘focus coverage.
- **Edgeâ€‘Optimized Export:** Pyramidal OMEâ€‘TIFF generation with Dask/Zarr that reduces processing time and peak RAM footprint to fit **NVIDIA Jetsonâ€‘class** devices.
- **Modular, Inline Processing:** Designed to run *inline* during scanning: estimate focus â†’ select sharp tiles â†’ assemble â†’ pyramidal export.
- **Rechunking for I/O Efficiency:** Smart chunk geometry for multiâ€‘resolution tiling and fast random access in downstream viewers.

> **Note on IP:** Some capture/stitching logic is covered by a patent. Please respect the license/IP notes below before redistribution or commercialization.

---

## ğŸ§­ Repository Snapshot

This ZIP contains a subset of the full project, focused on autofocus, accumulation utilities, and the OMEâ€‘TIFF pipeline.

```
Whole-Slide-Imaging-System-main/
â”œâ”€ DL_model.py        # ResNet-based focus regressor + training/inference helpers
â”œâ”€ img_acc.py         # Lightweight image/patch accumulator (double-ended queue)
â”œâ”€ packagep2.py       # Dask/Zarr-backed WSI data adapter and exporter
â””â”€ packages1.py       # Multiprocessing collection, raster/level registration, OMEâ€‘TIFF writer
```

### Key Modules & Classes

- **`ResNetFocusRegressor` (`DL_model.py`)**  
  - CNN regressor (ResNet backbone) with continuous focus prediction.  
  - Includes dataset/transform scaffolding (`InlineFocusDataset`), training loop (`train_inline_focus_model`), and inference (`predict_focus_distance`).

- **`d_que` (`img_acc.py`)**  
  - Minimal doubleâ€‘ended queue for patch/window accumulation with `append`, `popleft`, `trim`, and random access.

- **`wsi_da` (`packagep2.py`)**  
  - Dask/Zarr data abstraction for WSI pyramids.  
  - Provides `rechucking`, `save_as_zarr`, and `zarr_to_ome_tiff` to move from intermediate arrays â†’ Zarr â†’ OMEâ€‘TIFF.

- **`ProcessCollection` (`packages1.py`)**  
  - Multiprocessingâ€‘friendly collector for tile batches, with raster group registration and OMEâ€‘TIFF emission (`save_processed_images`).  
  - Static helper `zarr_process(queue, zarr_path, ome_tiff_path)` to run collection & export in a worker.

> Names and signatures above reflect the code in this archive; additional utilities (data loaders, device control, stitching heuristics, etc.) live in the full private repo.

---

## ğŸ”¬ Autofocus Model (Inline)

**Goal:** Predict the bestâ€‘focus offset from raw/nearâ€‘raw image patches so the stage can be driven proactively, reducing zâ€‘stacking and capture time.

**Approach:**
- Supervised regression with a ResNet backbone (see `ResNetFocusRegressor`).
- Data pipeline in `InlineFocusDataset` with torchvision transforms.
- Learningâ€‘rate scheduling via `ReduceLROnPlateau` for stable convergence.
- Exportable inference path `predict_focus_distance()` suitable for inline use.

**Why regression?**  
Continuous offsets preserve ordering information and allow subâ€‘step correction, which is critical for the reported **Â±0.002â€¯mm** accuracy target.

---

## ğŸ§µ Stitching & Capture Strategy (Patented)

The capture algorithm plans a path over the specimen with overlap tuned to the opticsâ€™ field curvature and depth of field. Inline focus scores select or reâ€‘capture tiles that miss the sharpness threshold. Neighborâ€‘aware blending is applied during assembly to avoid visible seams.

> For IPâ€‘protected pieces, this archive includes only the interfaces used by the exporter and accumulator.

---

## ğŸ—‚ï¸ Pyramidal OMEâ€‘TIFF Export

- **Intermediate Format:** Zarr arrays (chunked, compressed) for scalable outâ€‘ofâ€‘core processing.
- **Rechunking:** `wsi_da.rechucking()` optimizes chunk geometry per pyramid level for viewer access patterns.
- **Emission:** `wsi_da.zarr_to_ome_tiff()` writes standardsâ€‘compliant OMEâ€‘TIFF with multiple resolutions (pyramid levels).
- **Multiprocessing:** `ProcessCollection` gathers processed tiles from workers and persists them without exceeding Jetson memory budgets.

**Why OMEâ€‘TIFF?**  
Interoperable metadata + multiâ€‘resolution pyramids â†’ plugâ€‘andâ€‘play with common pathology viewers and analytics pipelines.

---

## ğŸ“ˆ Performance Notes

- **Focus Accuracy:** Â±0.002â€¯mm across multiâ€‘resolution slides (validated inline on representative datasets).  
- **Throughput:** Pyramidal export via Dask/Zarr significantly reduces wallâ€‘clock time compared to monolithic inâ€‘memory assembly.  
- **Memory Footprint:** Peak RAM reduced to operate within **NVIDIA Jetson** constraints by streaming tiles and avoiding large intermediate buffers.

> Exact numbers depend on optics, camera, tile size, pyramid depth, compression, and overlap ratio.

---

## ğŸ§© Typical Pipeline

1. **Tile acquisition** with stage control and camera SDK.  
2. **Inline focus prediction** with `ResNetFocusRegressor` â†’ select/correct.  
3. **Patch/Tile accumulation** with `d_que`.  
4. **WSI construction** into Zarr arrays using `wsi_da`.  
5. **Rechunk + Export** to pyramidal **OMEâ€‘TIFF**.  
6. **(Optional)** QC visualization & metadata audit.

```text
[Camera] â†’ [DL Autofocus] â†’ [Tile Buffer] â†’ [Zarr Pyramid]
                               â”‚                 â”‚
                           [Blend/Seam]      [OMEâ€‘TIFF]
```

---

## ğŸ“ Data & Annotations (Guidance)

- **Input:** Brightfield/fluorescence tile patches with known zâ€‘offsets for supervised training.  
- **Labels:** Continuous focus distances (Âµm/mm) or equivalent defocus proxy (e.g., objective steps).  
- **Augmentations:** Contrast, mild blur/jitter, intensity scaling; preserve focus ordering.  
- **QC:** Holdâ€‘out slide regions across staining conditions to avoid siteâ€‘specific bias.

> The archive does not include datasets. Use institutionâ€‘approved deâ€‘identified data only.

---

## ğŸ” Compliance & Ethics

- Follow institutional guidelines for handling clinical images.  
- Remove PHI/PII and respect consent policies.  
- Validate across staining protocols, scanners, magnifications, and tissue types before deployment.

---

## ğŸ”§ Extensibility

- Swap backbones (e.g., EfficientNet, ConvNeXt) for the regressor.  
- Add sharpness priors or selfâ€‘supervised objectives.  
- Integrate learned blending or seamâ€‘cutting for challenging tissues (fatty, folded, or sparse slides).  
- Plug in GPUâ€‘accelerated codecs and different compression schemes for pyramids.

---

## ğŸ“š Citations & Related Standards

- **OMEâ€‘TIFF / OMEâ€‘Zarr** (Open Microscopy Environment) standards.  
- **Dask/Zarr** for chunked, outâ€‘ofâ€‘core arrays.  
- **ResNet** family for CNN regression backbones.

/stitching strategy are **patentâ€‘protected**; redistribution and commercial use may require a separate agreement.  
- Trademarks belong to their respective owners.

---

### Acknowledgements

Thanks to contributors in microscopy/openâ€‘source imaging ecosystems (OME, Zarr, Dask, PyTorch, OpenCV) and to the pathology engineers who helped validate the inline autofocus at scale.
